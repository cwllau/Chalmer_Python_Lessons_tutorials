{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Python\n",
    "replace_with_topic\n",
    "\n",
    "<img src='../images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Title: Pandas Demo 2\n",
    "# Filename: pandas_demo_2.py\n",
    "# Usage: Run using IPython and associated demobatch.py script\n",
    "       # see demobatch.py for usage instructions\n",
    "# Description: How to use pandas to read data from csv files and sql\n",
    "             # databases.\n",
    "# Date: 20160301\n",
    "# Revision: 0.5\n",
    "# Python Version: 3.x\n",
    "# IPython Revision:: n/a\n",
    "# Author: Chalmer Lowe\n",
    "\n",
    "# TODO:\n",
    "# ==========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <demo> stop\n",
    "# When using pandas, it is common to import pandas as pd and to \n",
    "# simply import the factory functions: Series and DataFrames\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <demo> stop\n",
    "# Pandas is adept at reading in many, many data formats \n",
    "# To see which ones, you can type pd.read and use 'tab completion'\n",
    "# \n",
    "# pd.read<Press the tab key>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <demo> stop\n",
    "# Let's start by reading from the clipboard after we copy data from a\n",
    "# table on a webpage.\n",
    "\n",
    "webdata = pd.read_clipboard()\n",
    "webdata\n",
    "\n",
    "# Try some of the following:\n",
    "# webdata.C<press the tab key>\n",
    "# webdata.Column1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# <demo> stop\n",
    "# We will focus on csv and sql for remainder of this discussion\n",
    "# Let's dive into csv first.\n",
    "\n",
    "data = pd.read_csv('../../log_file.csv')\n",
    "data\n",
    "\n",
    "# In the results, notice the column headers. By default, pandas will use the first\n",
    "# row as a header row...  'barry allen' shows up a the header for column 1.\n",
    "# Maybe NOT what you want...\n",
    "#\n",
    "# <demo> stop\n",
    "# if we include a list of names in the function call, pandas will use those\n",
    "# as the headers instead of the first row.\n",
    "\n",
    "named_cols = pd.read_csv('../../log_file.csv', names=['name', 'email', 'fmip', 'toip',\n",
    "                                                     'datetime', 'lat', 'long', 'payload'])\n",
    "\n",
    "# named_cols.info()\n",
    "\n",
    "# <demo> stop\n",
    "# It is not necessary to ingest all the lines from a file. Presuming that certain lines lack\n",
    "# useful information... metadata, header lines, document data, etc.\n",
    "# in this case, let's skip rows 1, 2, 3, 7, and 9 from the csv.\n",
    "\n",
    "skipped_rows = pd.read_csv('../../log_file.csv', names=['name', 'email', 'fmip', 'toip',\n",
    "                            'datetime', 'lat', 'long', 'payload'],\n",
    "                            skiprows=[1, 2, 3, 7, 9])\n",
    "\n",
    "# And let's look at just one of the columns.\n",
    "skipped_rows.fmip\n",
    "\n",
    "# <demo> stop\n",
    "# You may receive files with alternate separators/delimiters. Pandas gives you tools to  \n",
    "# deal with this situation. This file uses a 'pipe' character as the separator.\n",
    "\n",
    "piped_data = pd.read_csv('../../log_file_pipes.csv', names=['name', 'email', 'fmip',\n",
    "                                  'toip', 'datetime', 'lat', 'long', 'payload'],\n",
    "                                  sep='|')\n",
    "\n",
    "# piped_data.tail(3)\n",
    "# piped_data.head(4)\n",
    "\n",
    "# <demo> stop\n",
    "# When reading in data, pandas assigns a default index of 0..n. Sometimes we want to use \n",
    "# something different than the default indexing.\n",
    "# We can choose a particular column to be used as an index.\n",
    "# Here we chose to use the datetime column\n",
    "\n",
    "date_index = pd.read_csv('../../log_file.csv', names=['name', 'email', 'fmip', 'toip',\n",
    "                         'datetime', 'lat', 'long', 'payload'],\n",
    "                         index_col='datetime')\n",
    "\n",
    "# <demo> stop\n",
    "# If we have an index, we can select data from the DataFrame based on the\n",
    "# index. In this case, since we just made the date/time our index, we can\n",
    "# easily select rows based on the date/time stamps\n",
    "\n",
    "date_index.ix['2016-02-06T21:44:56':'2016-02-06T21:49:36']\n",
    "\n",
    "# <demo> stop\n",
    "# Some files have missing data or markers indicating that data is not\n",
    "# available.\n",
    "\n",
    "data_na = pd.read_csv('../../log_file_na.csv', names=['name', 'email', 'fmip',\n",
    "                         'toip', 'datetime', 'lat', 'long', 'payload'])\n",
    "\n",
    "data_na\n",
    "# data_na.dropna()\n",
    "\n",
    "# <demo> stop\n",
    "# Checking for na status and converting the value to an NaN flag is a time\n",
    "# consuming process that might not be optimal for when loading data.\n",
    "# You _can_ turn this process off\n",
    "\n",
    "\n",
    "data_na = pd.read_csv('../../log_file_na.csv', names=['name', 'email', 'fmip',\n",
    "                         'toip', 'datetime', 'lat', 'long', 'payload'],\n",
    "                         na_filter=False)\n",
    "\n",
    "data_na\n",
    "\n",
    "\n",
    "# <demo> stop\n",
    "# You can provide a list of particular values to use as na values. Some files\n",
    "# or software will use sentinels or flag values to represent a null value.\n",
    "data_na = pd.read_csv('../../log_file_na.csv', names=['name', 'email', 'fmip',\n",
    "                         'toip', 'datetime', 'lat', 'long', 'payload'],\n",
    "                         na_values=['', '9999'])\n",
    "# data_na\n",
    "\n",
    "# NOTE: in this case, it will combine the na_values you give with the built-in na\n",
    "# values.\n",
    "\n",
    "# <demo> stop\n",
    "data_na = pd.read_csv('../../log_file_na.csv', names=['name', 'email', 'fmip',\n",
    "                         'toip', 'datetime', 'lat', 'long', 'payload'],\n",
    "                         na_values=['', '9999'], keep_default_na=False)\n",
    "\n",
    "# data_na\n",
    "\n",
    "# <demo> stop\n",
    "data_na = pd.read_csv('../../log_file_na.csv', names=['name', 'email', 'fmip',\n",
    "                         'toip', 'datetime', 'lat', 'long', 'payload'],\n",
    "                         na_values=['', '9999'], keep_default_na=False,\n",
    "                         nrows=15)\n",
    "# data_na\n",
    "\n",
    "# <demo> stop\n",
    "data = pd.read_csv('../../log_file.csv', names=['name', 'email', 'fmip', 'toip',\n",
    "                           'datetime', 'lat', 'long', 'payload'], chunksize=3)\n",
    "\n",
    "for chunk in data:\n",
    "    print('\\npre-processing')\n",
    "    print('more pre-processing')\n",
    "    print('even more pre-processing')\n",
    "    print(chunk)\n",
    "    print('post processing\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# <demo> stop\n",
    "# If you want to convert data in one of your columns, you can use a dictionary\n",
    "# to define which conversion function(s) to use against which columns(s)\n",
    "def dsplitter(address):\n",
    "    userid, domain = address.split('@')\n",
    "    return userid, domain\n",
    "\n",
    "def date_only(datetime):\n",
    "    return datetime.split('T')[0]\n",
    "\n",
    "data = pd.read_csv('../../log_file.csv', names=['name', 'email', 'fmip', 'toip',\n",
    "                           'datetime', 'lat', 'long', 'payload'],\n",
    "                           converters={'email':dsplitter, 'datetime':date_only})\n",
    "# data\n",
    "\n",
    "# <demo> stop\n",
    "data = pd.read_csv('../../log_file.csv', names=['name', 'email', 'fmip', 'toip',\n",
    "                           'datetime', 'lat', 'long', 'payload'],\n",
    "                           usecols=['email', 'fmip', 'toip'])\n",
    "\n",
    "# data\n",
    "\n",
    "# <demo> stop\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('../../log_file.sql')\n",
    "cur = conn.cursor()\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM superheroes\", conn)\n",
    "\n",
    "# <demo> stop\n",
    "df1 = pd.read_sql('''SELECT datetime, email, lat, long FROM superheroes\n",
    "                          WHERE name LIKE \"%wayne%\"''', conn)\n",
    "\n",
    "\n",
    "# <demo> stop\n",
    "df2 = pd.read_sql('''SELECT datetime, email, lat, long FROM superheroes\n",
    "                          WHERE name LIKE \"%wayne%\"''', conn, index_col='datetime')\n",
    "\n",
    "# <demo> stop\n",
    "df2.to_csv('class_out.csv',\n",
    "                  cols=['email', 'lat', 'long', 'name'],\n",
    "                  header=True, sep='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
